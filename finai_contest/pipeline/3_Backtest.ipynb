{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7Cycmf3Zbok"
   },
   "source": [
    "# Stock NeurIPS2018 Part 3. Backtest\n",
    "This series is a reproduction of paper *the process in the paper Practical Deep Reinforcement Learning Approach for Stock Trading*. \n",
    "\n",
    "This is the third and last part of the NeurIPS2018 series, introducing how to use use the agents we trained to do backtest, and compare with baselines such as Mean Variance Optimization and DJIA index.\n",
    "\n",
    "Other demos can be found at the repo of [FinRL-Tutorials]((https://github.com/AI4Finance-Foundation/FinRL-Tutorials))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oWbj4HgqHBg"
   },
   "source": [
    "# Part 1. Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJgoEYx3p_NG"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqfBOKz-qJYF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR\n",
    "\n",
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path.cwd().parents[1]))\n",
    "from finai_contest.env_stock_trading.env_stock_trading_finrlmeta import StockTradingEnv_FinRLMeta\n",
    "from finai_contest.env_stock_trading.env_stock_trading_gym_anytrading import StockTradingEnv_gym_anytrading\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUF2P4hmqVjh"
   },
   "source": [
    "# Part 2. Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdU6qLsVWDxI"
   },
   "source": [
    "To backtest the agents, upload trade_data.csv in the same directory of this notebook. For Colab users, just upload trade_data.csv to the default directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSjBHn_MZr4U"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_data.csv')\n",
    "trade = pd.read_csv('./data/trade_data.csv')\n",
    "\n",
    "# If you are not using the data generated from part 1 of this tutorial, make sure \n",
    "# it has the columns and index in the form that could be make into the environment. \n",
    "# Then you can comment and skip the following lines.\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']\n",
    "trade_aapl = trade[trade[\"tic\"] == \"AAPL\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu4Ey54b36oL"
   },
   "source": [
    "Then, upload the trained agent to the same directory, and set the corresponding variable to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_mVZM4IIa55"
   },
   "outputs": [],
   "source": [
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73D4oRqAIkYj"
   },
   "source": [
    "Load the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_used = \"finrl\"\n",
    "env_used = \"gym_anytrading\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CagrX0I36ZN"
   },
   "outputs": [],
   "source": [
    "trained_a2c = A2C.load(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n",
    "trained_ddpg = DDPG.load(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n",
    "trained_ppo = PPO.load(TRAINED_MODEL_DIR + \"/agent_ppo_\"+env_used) if if_using_ppo else None\n",
    "trained_td3 = TD3.load(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n",
    "trained_sac = SAC.load(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trading (Out-of-sample Performance)\n",
    "\n",
    "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4H_w3SaBAkKU",
    "outputId": "fdaed3a7-d3a9-4cde-d194-ee4576057175"
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(trade_aapl.tic.unique())\n",
    "if env_used == \"finrl\":\n",
    "    state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
    "    buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "elif env_used == \"gym_anytrading\":\n",
    "    state_space = 1 + 3 * stock_dimension\n",
    "    buy_cost_list = [0.005] * stock_dimension\n",
    "    sell_cost_list = [0.01] * stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKNmQMqGAknW"
   },
   "outputs": [],
   "source": [
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "if env_used ==\"finrl\":\n",
    "    env_kwargs = {\n",
    "        \"hmax\": 100,\n",
    "        \"initial_amount\": 1000000,\n",
    "        \"num_stock_shares\": num_stock_shares,\n",
    "        \"buy_cost_pct\": buy_cost_list,\n",
    "        \"sell_cost_pct\": sell_cost_list,\n",
    "        \"state_space\": state_space,\n",
    "        \"stock_dim\": stock_dimension,\n",
    "        \"tech_indicator_list\": INDICATORS,\n",
    "        \"action_space\": stock_dimension,\n",
    "        \"reward_scaling\": 1e-4\n",
    "    }\n",
    "\n",
    "\n",
    "    e_trade_gym = StockTradingEnv_FinRLMeta(df = trade_aapl, **env_kwargs)\n",
    "\n",
    "elif env_used ==\"gym_anytrading\":\n",
    "    env_kwargs = {\n",
    "    \"hmax\": np.inf,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": 2*stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"window_size\": 30\n",
    "    }\n",
    "\n",
    "    e_trade_gym = StockTradingEnv_gym_anytrading(df = trade_aapl, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trade_aapl = trade[trade[\"tic\"] == \"AAPL\"]\n",
    "# trade_gym_anytrade = pd.DataFrame()\n",
    "# trade_gym_anytrade['Time'] = pd.to_datetime(trade_aapl['date'])  # Convert to datetime\n",
    "# trade_gym_anytrade['Open'] = trade_aapl['open']\n",
    "# trade_gym_anytrade['High'] = trade_aapl['high']\n",
    "# trade_gym_anytrade['Low'] = trade_aapl['low']\n",
    "# trade_gym_anytrade['Close'] = trade_aapl['close']\n",
    "# trade_gym_anytrade['Volume'] = trade_aapl['volume']\n",
    "# trade_aapl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "# import gymnasium as gym\n",
    "# import gym_anytrading\n",
    "\n",
    "# e_trade_gym = gym.make(\n",
    "#     'stocks-v0',\n",
    "#     df=trade_gym_anytrade,\n",
    "#     window_size=30,\n",
    "#     frame_bound=(30, len(trade_gym_anytrade))\n",
    "# )\n",
    "\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# def get_sb_env(self):\n",
    "#     e = DummyVecEnv([lambda: self])\n",
    "#     obs = e.reset()\n",
    "#     return e, obs\n",
    "\n",
    "\n",
    "# def save_asset_memory(self):\n",
    "#     if \"total_profit\" not in self.history:\n",
    "#         print(\"Warning: 'total_profit' not found in history. Returning empty DataFrame.\")\n",
    "#         return pd.DataFrame({\"date\": [], \"account_value\": []})\n",
    "#     dates = self.df['Time'][self._start_tick:self._current_tick].dt.strftime('%Y-%m-%d')\n",
    "#     profits = self.history[\"total_profit\"]\n",
    "\n",
    "#     assert len(dates) == len(profits), f\"Length mismatch: {len(dates)} dates vs {len(profits)} profits\"\n",
    "\n",
    "#     df_account_value = pd.DataFrame({\n",
    "#         \"date\": dates,\n",
    "#         \"account_value\": profits\n",
    "#     })\n",
    "#     return df_account_value\n",
    "\n",
    "\n",
    "# def save_action_memory(self):\n",
    "#     if \"total_profit\" not in self.history:\n",
    "#         print(\"Warning: 'total_profit' not found in history. Returning empty DataFrame.\")\n",
    "#         return pd.DataFrame({\"date\": [], \"account_value\": []})\n",
    "#     dates = self.df['Time'][self._start_tick:self._current_tick].dt.strftime('%Y-%m-%d')\n",
    "#     actions = self.history[\"position\"]\n",
    "\n",
    "#     assert len(dates) == len(actions), f\"Length mismatch: {len(dates)} dates vs {len(actions)} profits\"\n",
    "\n",
    "#     df_account_value = pd.DataFrame({\n",
    "#         \"date\": dates,\n",
    "#         \"action\": actions\n",
    "#     })\n",
    "#     return df_account_value\n",
    "\n",
    "# # Patch the method\n",
    "# e_trade_gym = e_trade_gym.env.env\n",
    "# e_trade_gym.get_sb_env = get_sb_env.__get__(e_trade_gym)\n",
    "# e_trade_gym.save_asset_memory = save_asset_memory.__get__(e_trade_gym)\n",
    "# e_trade_gym.save_action_memory = save_action_memory.__get__(e_trade_gym)\n",
    "# e_trade_gym.get_sb_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbFchno5j3xs",
    "outputId": "44fffa47-3b47-4e7b-96c2-0a485e9efead"
   },
   "outputs": [],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbYljWGjj3pH"
   },
   "outputs": [],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74jNP2DBj3hb"
   },
   "outputs": [],
   "source": [
    "df_account_value_ppo_list = []\n",
    "df_actions_ppo_list = []\n",
    "for i in range(1):\n",
    "    df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "        model=trained_ppo, \n",
    "        environment = e_trade_gym, deterministic=False) if if_using_ppo else (None, None)\n",
    "    df_account_value_ppo_list.append(df_account_value_ppo)\n",
    "    df_actions_ppo_list.append(df_actions_ppo)\n",
    "    # print(df_account_value_ppo_list)\n",
    "\n",
    "df_account_value_all = pd.concat([df.set_index(\"date\")[\"account_value\"] for df in df_account_value_ppo_list],axis=1)\n",
    "df_account_value_all.columns = [f\"run_{i+1}\" for i in range(len(df_account_value_ppo_list))]\n",
    "df_account_value_all['mean'] = df_account_value_all.mean(axis=1)\n",
    "df_account_value_all['std'] = df_account_value_all.std(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo = df_account_value_all[['mean', 'std']].reset_index()\n",
    "df_account_value_ppo.columns = ['date', 'account_value', 'std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"./results_csv\", exist_ok=True)\n",
    "df_account_value_ppo.to_csv(\"./results_csv/account_value_ppo_\"+env_used+\".csv\", index=False)\n",
    "print(df_account_value_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7VyGGJPj3SH"
   },
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLOnL5eYh1jR",
    "outputId": "70e50e24-aed5-49f9-cdd7-de6b9689d9ce"
   },
   "outputs": [],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_sharpe_ratio(total_profits):\n",
    "    total_profits = np.array(total_profits)\n",
    "    \n",
    "    # Calculate daily returns (percentage change)\n",
    "    daily_returns = np.diff(total_profits) / total_profits[:-1]\n",
    "    \n",
    "    if daily_returns.std() == 0 or len(daily_returns) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    sharpe = (255 ** 0.5) * daily_returns.mean() / daily_returns.std()\n",
    "    return sharpe\n",
    "\n",
    "print(\"Sharpe Ratio:\",_calculate_sharpe_ratio(df_account_value_ppo[\"account_value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure 'date' is in datetime format (optional, for better x-axis formatting)\n",
    "df_account_value_ppo['date'] = pd.to_datetime(df_account_value_ppo['date'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_account_value_ppo['date'], df_account_value_ppo['account_value'], label='Account Value (PPO)', linewidth=2)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Account Value')\n",
    "plt.title('PPO Trading Strategy: Account Value Over Time')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcE-t08w6DaW"
   },
   "source": [
    "# Part 3: Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17TUs71EWj09"
   },
   "source": [
    "Mean Variance optimization is a very classic strategy in portfolio management. Here, we go through the whole process to do the mean variance optimization and add it as a baseline to compare.\n",
    "\n",
    "First, process dataframe to the form for MVO weight calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wungSNOwPwKR"
   },
   "outputs": [],
   "source": [
    "def process_df_for_mvo(df):\n",
    "  return df.pivot(index=\"date\", columns=\"tic\", values=\"close\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwEwkHJ1d_6u"
   },
   "source": [
    "### Helper functions for mean returns and variance-covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KvXkpyE8MFq"
   },
   "outputs": [],
   "source": [
    "# Codes in this section partially refer to Dr G A Vijayalakshmi Pai\n",
    "# https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios/notebook\n",
    "\n",
    "def StockReturnsComputing(StockPrice, Rows, Columns): \n",
    "  import numpy as np \n",
    "  StockReturn = np.zeros([Rows-1, Columns]) \n",
    "  for j in range(Columns):        # j: Assets \n",
    "    for i in range(Rows-1):     # i: Daily Prices \n",
    "      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100 \n",
    "      \n",
    "  return StockReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeVVbuwveJ_5"
   },
   "source": [
    "### Calculate the weights for mean-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE8nruKLQYLO",
    "outputId": "42d07c80-f309-49f8-f2b4-36a51987086f"
   },
   "outputs": [],
   "source": [
    "StockData = process_df_for_mvo(train)\n",
    "TradeData = process_df_for_mvo(trade)\n",
    "\n",
    "TradeData.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6_O6vrn_uD4",
    "outputId": "0c2f8bf7-07e7-4fe5-c409-93312b95a8dd"
   },
   "outputs": [],
   "source": [
    "#compute asset returns\n",
    "arStockPrices = np.asarray(StockData)\n",
    "[Rows, Cols]=arStockPrices.shape\n",
    "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "#compute mean returns and variance covariance matrix of returns\n",
    "meanReturns = np.mean(arReturns, axis = 0)\n",
    "covReturns = np.cov(arReturns, rowvar=False)\n",
    " \n",
    "#set precision for printing results\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "#display mean returns and variance-covariance matrix of returns\n",
    "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "print('Variance-Covariance matrix of returns\\n', covReturns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zC7r-cI8RR1X"
   },
   "source": [
    "### Use PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1btTONEdCU4",
    "outputId": "75096462-7dfb-4ce6-c6f4-4671f11e79fc"
   },
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "raw_weights_mean = ef_mean.max_sharpe()\n",
    "cleaned_weights_mean = ef_mean.clean_weights()\n",
    "mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(len(cleaned_weights_mean))])\n",
    "mvo_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F38NJRJJgOmj",
    "outputId": "f575651b-1e9b-4015-ae71-c9fc2c3a3dae"
   },
   "outputs": [],
   "source": [
    "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "Initial_Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAd1iXqZhQ6X"
   },
   "outputs": [],
   "source": [
    "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "MVO_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5sgGe7g1HsL"
   },
   "source": [
    "# Part 4: DJIA index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVe_ufxTY2CW"
   },
   "source": [
    "Add DJIA index as a baseline to compare with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sACPzsI-6k8q"
   },
   "outputs": [],
   "source": [
    "# TRAIN_START_DATE = '2009-01-01'\n",
    "# TRAIN_END_DATE = '2020-07-01'\n",
    "# TRADE_START_DATE = '2020-07-01'\n",
    "# TRADE_END_DATE = '2021-10-29'\n",
    "TRAIN_START_DATE = '2009-01-01'\n",
    "TRAIN_END_DATE = '2023-01-01'\n",
    "TRADE_START_DATE = '2023-01-01'\n",
    "TRADE_END_DATE = '2024-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuszW-OB1K0m",
    "outputId": "b89a8350-de58-4fea-8e4b-856efa872712"
   },
   "outputs": [],
   "source": [
    "df_dji = YahooDownloader(\n",
    "    start_date=TRADE_START_DATE, end_date=TRADE_END_DATE, ticker_list=[\"^DJI\"]\n",
    ").fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3RXz72U1VbV"
   },
   "outputs": [],
   "source": [
    "df_dji = df_dji[[\"date\", \"close\"]]\n",
    "fst_day = df_dji[\"close\"][0]\n",
    "dji = pd.merge(\n",
    "    df_dji[\"date\"],\n",
    "    df_dji[\"close\"].div(fst_day).mul(1000000),\n",
    "    how=\"outer\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Equally Weighted Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "  return df.pivot(index=\"date\", columns=\"tic\", values=\"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StockData = process_df(train)\n",
    "TradeData = process_df(trade)\n",
    "\n",
    "TradeData.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = TradeData.to_numpy()\n",
    "T, N = trade_data.shape\n",
    "\n",
    "# Initialize portfolio\n",
    "portfolio_value = [1000000]\n",
    "weights = np.ones(N) / N  # equal weights\n",
    "\n",
    "for t in range(1, T):\n",
    "    # Previous prices and today's prices\n",
    "    prev_prices = trade_data[t - 1]\n",
    "    curr_prices = trade_data[t]\n",
    "\n",
    "    # How many shares of each asset we held yesterday\n",
    "    shares = (portfolio_value[-1] * weights) / prev_prices\n",
    "\n",
    "    # Today's value = shares * today's price\n",
    "    new_value = np.sum(shares * curr_prices)\n",
    "\n",
    "    portfolio_value.append(new_value)\n",
    "\n",
    "TradeData.index = pd.to_datetime(TradeData.index)\n",
    "\n",
    "# Step 2: Convert your portfolio_value into a DataFrame\n",
    "EWS_result = pd.DataFrame(\n",
    "    portfolio_value, \n",
    "    index=TradeData.index,   # align with dates\n",
    "    columns=[\"Equal Weight\"] # name the strategy\n",
    ")\n",
    "EWS_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 6: Backtesting Results\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeDeGAc9VrEg"
   },
   "outputs": [],
   "source": [
    "df_result_a2c = (\n",
    "    df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "    if if_using_a2c\n",
    "    else None\n",
    ")\n",
    "df_result_ddpg = (\n",
    "    df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "    if if_using_ddpg\n",
    "    else None\n",
    ")\n",
    "df_result_ppo = (\n",
    "    df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "    if if_using_ppo\n",
    "    else None\n",
    ")\n",
    "df_result_td3 = (\n",
    "    df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "    if if_using_td3\n",
    "    else None\n",
    ")\n",
    "df_result_sac = (\n",
    "    df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "    if if_using_sac\n",
    "    else None\n",
    ")\n",
    "df_result_ppo.index = pd.to_datetime(df_result_ppo.index)\n",
    "MVO_result.index = pd.to_datetime(MVO_result.index)\n",
    "dji.index = pd.to_datetime(dji.index)\n",
    "print(df_result_ppo[\"account_value\"])\n",
    "print(MVO_result[\"Mean Var\"])\n",
    "print(df_result_ppo[\"account_value\"].apply(type).unique())\n",
    "print(MVO_result[\"Mean Var\"].apply(type).unique())\n",
    "print(dji[\"close\"].apply(type).unique())\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"a2c\": df_result_a2c[\"account_value\"] if if_using_a2c else None,\n",
    "        \"ddpg\": df_result_ddpg[\"account_value\"] if if_using_ddpg else None,\n",
    "        \"ppo\": df_result_ppo[\"account_value\"] if if_using_ppo else None,\n",
    "        \"td3\": df_result_td3[\"account_value\"] if if_using_td3 else None,\n",
    "        \"sac\": df_result_sac[\"account_value\"] if if_using_sac else None,\n",
    "        \"mvo\": MVO_result[\"Mean Var\"],\n",
    "        \"dji\": dji[\"close\"],\n",
    "        \"ews\": EWS_result[\"Equal Weight\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "trading_days_per_year = 252\n",
    "\n",
    "# === Utility Functions ===\n",
    "def compute_annualized_return(v0, vT, T):\n",
    "    return (1+((vT - v0)/ v0))** (365 / T) - 1\n",
    "\n",
    "def compute_sharpe_ratio(daily_returns):\n",
    "    if daily_returns.std() == 0 or len(daily_returns) < 2:\n",
    "        return 0.0\n",
    "    return daily_returns.mean() / daily_returns.std() * np.sqrt(trading_days_per_year)\n",
    "\n",
    "def compute_annualized_volatility(daily_returns):\n",
    "    return daily_returns.std() * np.sqrt(trading_days_per_year)\n",
    "\n",
    "def compute_max_drawdown(daily_returns):\n",
    "    r = np.asarray(daily_returns, dtype=float)\n",
    "    if r.size == 0:\n",
    "        return 0.0\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size == 0:\n",
    "        return 0.0\n",
    "    equity = np.cumprod(1.0 + r)\n",
    "    peaks = np.maximum.accumulate(equity)\n",
    "    drawdowns = equity / peaks - 1.0  # ≤ 0\n",
    "    return float(np.min(drawdowns) * 100.0)\n",
    "# === Initialize Metrics Dictionary ===\n",
    "metrics = {}\n",
    "\n",
    "# === Process Baselines ===\n",
    "for strategy in result.columns.drop('ppo'):\n",
    "    series = result[strategy].dropna()\n",
    "    if len(series) < 2:\n",
    "        continue\n",
    "\n",
    "    daily_returns = series.pct_change().dropna()\n",
    "    final_value = series.iloc[-1]\n",
    "    v0 = series.iloc[0]\n",
    "    T = len(series)\n",
    "    print(\"baseline trade\",T)\n",
    "    print(strategy,v0,final_value)\n",
    "    annual_return = compute_annualized_return(v0, final_value, T)\n",
    "    volatility = compute_annualized_volatility(daily_returns)\n",
    "    sharpe = compute_sharpe_ratio(daily_returns)\n",
    "    max_drawdown = compute_max_drawdown(daily_returns)\n",
    "    metrics[strategy] = {\n",
    "        \"Final Value\": final_value,\n",
    "        \"Annualized Return\": annual_return,\n",
    "        \"Annualized Volatility\": volatility,\n",
    "        \"Annualized StdErr\": np.nan,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Maximum Drawdown\":max_drawdown,\n",
    "    }\n",
    "\n",
    "# === Process PPO Multi-run ===\n",
    "ppo_runs = [df_account_value_all[f'run_{i+1}'] for i in range(1)]\n",
    "ppo_final_values = []\n",
    "ppo_annual_returns = []\n",
    "ppo_sharpe_ratios = []\n",
    "ppo_volatilities = []\n",
    "ppo_max_drawdown = []\n",
    "for series in ppo_runs:\n",
    "    series = series.dropna()\n",
    "    v0 = series.iloc[0]\n",
    "    vT = series.iloc[-1]\n",
    "    T = len(series)\n",
    "    print(\"agent trade\",T)\n",
    "\n",
    "    daily_returns = series.pct_change().dropna()\n",
    "\n",
    "    ppo_final_values.append(vT)\n",
    "    ppo_annual_returns.append(compute_annualized_return(v0, vT, T))\n",
    "    ppo_sharpe_ratios.append(compute_sharpe_ratio(daily_returns))\n",
    "    ppo_volatilities.append(daily_returns.std() * np.sqrt(252)) \n",
    "    ppo_max_drawdown.append(compute_max_drawdown(daily_returns))\n",
    "# Convert to arrays\n",
    "ppo_annual_returns = np.array(ppo_annual_returns)\n",
    "ppo_sharpe_ratios = np.array(ppo_sharpe_ratios)\n",
    "ppo_final_values = np.array(ppo_final_values)\n",
    "ppo_volatilities = np.array(ppo_volatilities)\n",
    "ppo_max_drawdown = np.array(ppo_max_drawdown)\n",
    "\n",
    "# Compute stats\n",
    "mean_volatility = ppo_volatilities.mean()\n",
    "std_volatility = ppo_volatilities.std(ddof=1)\n",
    "\n",
    "mean_final_value = ppo_final_values.mean()\n",
    "std_final_value = ppo_final_values.std(ddof=1)\n",
    "mean_annual_return = ppo_annual_returns.mean()\n",
    "std_annual_return = ppo_annual_returns.std(ddof=1)\n",
    "stderr_annual_return = std_annual_return / np.sqrt(len(ppo_annual_returns))\n",
    "mean_sharpe = ppo_sharpe_ratios.mean()\n",
    "std_sharpe = ppo_sharpe_ratios.std(ddof=1)\n",
    "mean_max_drawdown = ppo_max_drawdown.mean()\n",
    "\n",
    "# Save PPO to metrics\n",
    "metrics['ppo'] = {\n",
    "    \"Final Value\": f\"{mean_final_value:.2f}\",\n",
    "    \"Annualized Return\": f\"{mean_annual_return:.4f}\",\n",
    "    \"Annualized Volatility\": f\"{mean_volatility:.4f}\",\n",
    "    \"Annualized StdErr\": f\"{stderr_annual_return:.4f}\",\n",
    "    \"Sharpe Ratio\": f\"{mean_sharpe:.4f}\",\n",
    "    \"Maximum Drawdown\": f\"{mean_max_drawdown:.4f}\"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# === Final DataFrame ===\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "l4FZxyDt3XaE",
    "outputId": "2e739637-bf88-4698-9cf1-9a526452e465"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQuc5hI9Yklt"
   },
   "source": [
    "Now, everything is ready, we can plot the backtest result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "6xRfrqK4RVfq",
    "outputId": "469c9729-fd57-417c-9b13-2243426923e2"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GfZ5vY5wRjkJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
